{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['/Users/chandrayeebasu/Documents/insight/project/sgan/datasets/eth/train/students003_train.txt', '/Users/chandrayeebasu/Documents/insight/project/sgan/datasets/eth/train/biwi_hotel_train.txt', '/Users/chandrayeebasu/Documents/insight/project/sgan/datasets/eth/train/crowds_zara01_train.txt', '/Users/chandrayeebasu/Documents/insight/project/sgan/datasets/eth/train/uni_examples_train.txt', '/Users/chandrayeebasu/Documents/insight/project/sgan/datasets/eth/train/crowds_zara02_train.txt', '/Users/chandrayeebasu/Documents/insight/project/sgan/datasets/eth/train/students001_train.txt', '/Users/chandrayeebasu/Documents/insight/project/sgan/datasets/eth/train/crowds_zara03_train.txt']\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import math\n",
    "\n",
    "data_dir = '/Users/chandrayeebasu/Documents/insight/project/sgan/datasets/eth/train/'\n",
    "all_files = os.listdir(data_dir)\n",
    "all_files = [os.path.join(data_dir, _path) for _path in all_files]\n",
    "print(all_files)\n",
    "pred_len = 12\n",
    "obs_len = 8\n",
    "threshold = 0.002\n",
    "min_ped = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def read_file(_path, delim='\\t'):\n",
    "    data = []\n",
    "    if delim == 'tab':\n",
    "        delim = '\\t'\n",
    "    elif delim == 'space':\n",
    "        delim = ' '\n",
    "    with open(_path, 'r') as f:\n",
    "        for line in f:\n",
    "            line = line.strip().split(delim)\n",
    "            line = [float(i) for i in line]\n",
    "            data.append(line)\n",
    "    return np.asarray(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def poly_fit(traj, traj_len, threshold):\n",
    "    \"\"\"\n",
    "    Input:\n",
    "    - traj: Numpy array of shape (2, traj_len)\n",
    "    - traj_len: Len of trajectory\n",
    "    - threshold: Minimum error to be considered for non linear traj\n",
    "    Output:\n",
    "    - int: 1 -> Non Linear 0-> Linear\n",
    "    \"\"\"\n",
    "    t = np.linspace(0, traj_len - 1, traj_len) #linspace(start, stop, number)\n",
    "    res_x = np.polyfit(t, traj[0, -traj_len:], 2, full=True)[1] #returns residual for a polynomial fit for x pos\n",
    "    res_y = np.polyfit(t, traj[1, -traj_len:], 2, full=True)[1] #same for y pos \n",
    "    if res_x + res_y >= threshold:\n",
    "        return 1.0\n",
    "    else:\n",
    "        return 0.0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/chandrayeebasu/Documents/insight/project/sgan/datasets/eth/train/students003_train.txt\n",
      "432  frames\n",
      "/Users/chandrayeebasu/Documents/insight/project/sgan/datasets/eth/train/biwi_hotel_train.txt\n",
      "934  frames\n",
      "/Users/chandrayeebasu/Documents/insight/project/sgan/datasets/eth/train/crowds_zara01_train.txt\n",
      "697  frames\n",
      "/Users/chandrayeebasu/Documents/insight/project/sgan/datasets/eth/train/uni_examples_train.txt\n",
      "587  frames\n",
      "/Users/chandrayeebasu/Documents/insight/project/sgan/datasets/eth/train/crowds_zara02_train.txt\n",
      "841  frames\n",
      "/Users/chandrayeebasu/Documents/insight/project/sgan/datasets/eth/train/students001_train.txt\n",
      "355  frames\n",
      "/Users/chandrayeebasu/Documents/insight/project/sgan/datasets/eth/train/crowds_zara03_train.txt\n",
      "603  frames\n",
      "done\n",
      "(29809, 2, 20)\n",
      "(29809, 20)\n",
      "[[2.273  2.4572 2.6413 2.8255 2.8735 2.8876 2.9017 2.9156 2.9297 2.9438\n",
      "  2.9577 2.9718 2.9859 2.9998 3.0139 3.028  3.0419 3.056  3.0701 3.0839]\n",
      " [6.2052 6.3171 6.4288 6.5407 6.5646 6.5665 6.5684 6.5703 6.5722 6.5739\n",
      "  6.5758 6.5777 6.5796 6.5815 6.5834 6.5853 6.587  6.5889 6.5908 6.5927]]\n",
      "[29809. 29809. 29809. 29809. 29809. 29809. 29809. 29809. 29809. 29809.\n",
      " 29809. 29809. 29809. 29809. 29809. 29809. 29809. 29809. 29809. 29809.]\n"
     ]
    }
   ],
   "source": [
    "import pdb\n",
    "\n",
    "num_peds_in_seq = []\n",
    "seq_list = []\n",
    "seq_list_rel = []\n",
    "loss_mask_list = []\n",
    "non_linear_ped = []\n",
    "for path in all_files:\n",
    "    print(path)\n",
    "    data = read_file(path)\n",
    "    frames = np.unique(data[:, 0]).tolist()\n",
    "    frame_data = []\n",
    "    for frame in frames:\n",
    "        frame_data.append(data[frame == data[:, 0], :])\n",
    "    print(len(frames), ' frames')\n",
    "    skip = 1\n",
    "    seq_len = 20\n",
    "    num_sequences = int(math.ceil((len(frames) - seq_len + 1) / skip))\n",
    "    for idx in range(0, num_sequences * skip + 1, skip):\n",
    "        curr_seq_data = np.concatenate(frame_data[idx:idx + seq_len], axis=0)\n",
    "        peds_in_curr_seq = np.unique(curr_seq_data[:, 1]) #pedestrian ids per sequence (of frames)\n",
    "        curr_seq_rel = np.zeros((len(peds_in_curr_seq), 2, seq_len))\n",
    "        curr_seq = np.zeros((len(peds_in_curr_seq), 2, seq_len))\n",
    "        curr_loss_mask = np.zeros((len(peds_in_curr_seq),seq_len))\n",
    "        num_peds_considered = 0\n",
    "        _non_linear_ped = []\n",
    "        for _, ped_id in enumerate(peds_in_curr_seq):\n",
    "            curr_ped_seq = curr_seq_data[curr_seq_data[:, 1] ==\n",
    "                                         ped_id, :]\n",
    "            curr_ped_seq = np.around(curr_ped_seq, decimals=4)\n",
    "            pad_front = frames.index(curr_ped_seq[0, 0]) - idx\n",
    "            pad_end = frames.index(curr_ped_seq[-1, 0]) - idx + 1\n",
    "            if pad_end - pad_front != seq_len:\n",
    "                continue\n",
    "            curr_ped_seq = np.transpose(curr_ped_seq[:, 2:])\n",
    "            curr_ped_seq = curr_ped_seq #shape = (2, seq_len) matrix: xpos row, ypos row for each pedestrian id\n",
    "            # Make coordinates relative\n",
    "            rel_curr_ped_seq = np.zeros(curr_ped_seq.shape)\n",
    "            rel_curr_ped_seq[:, 1:] = \\\n",
    "                curr_ped_seq[:, 1:] - curr_ped_seq[:, :-1] #normalized per sequence\n",
    "            _idx = num_peds_considered\n",
    "            curr_seq[_idx, :, pad_front:pad_end] = curr_ped_seq\n",
    "            curr_seq_rel[_idx, :, pad_front:pad_end] = rel_curr_ped_seq\n",
    "            # Linear vs Non-Linear Trajectory\n",
    "            _non_linear_ped.append(\n",
    "                poly_fit(curr_ped_seq, pred_len, threshold))\n",
    "            curr_loss_mask[_idx, pad_front:pad_end] = 1\n",
    "            num_peds_considered += 1\n",
    "\n",
    "        if num_peds_considered > min_ped:\n",
    "            non_linear_ped += _non_linear_ped\n",
    "            num_peds_in_seq.append(num_peds_considered)\n",
    "            loss_mask_list.append(curr_loss_mask[:num_peds_considered])\n",
    "            seq_list.append(curr_seq[:num_peds_considered])\n",
    "            seq_list_rel.append(curr_seq_rel[:num_peds_considered])\n",
    "\n",
    "            \n",
    "print('done')   \n",
    "num_seq = len(seq_list)\n",
    "seq_list = np.concatenate(seq_list, axis=0)\n",
    "seq_list_rel = np.concatenate(seq_list_rel, axis=0)\n",
    "loss_mask_list = np.concatenate(loss_mask_list, axis=0)\n",
    "non_linear_ped = np.asarray(non_linear_ped)\n",
    "print(seq_list.shape)\n",
    "print(loss_mask_list.shape)\n",
    "obs_traj = seq_list[:,:,:obs_len]\n",
    "print(seq_list[1,:,:])\n",
    "print(sum(loss_mask_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.35627098]\n"
     ]
    }
   ],
   "source": [
    "traj_len = 5\n",
    "traj = np.random.randn(5)\n",
    "t = np.linspace(0, traj_len - 1, 5)\n",
    "res_x = np.polyfit(t, traj, 2, full=True)[1]\n",
    "print(res_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "fdir = '/Users/chandrayeebasu/Documents/insight/carladata/data/ma_datum_00000000.json'\n",
    "with open(fdir) as f:\n",
    "    d = json.load(f)\n",
    "for keys in d:\n",
    "    print(keys)\n",
    "agent_pasts = np.asarray(d['agent_pasts'])\n",
    "agent_futures = np.asarray(d['agent_futures'])\n",
    "player_past = np.asarray(d['player_past'])\n",
    "player_future = np.asarray(d['player_future'])\n",
    "print(agent_pasts.shape)\n",
    "#print(player_past.shape)\n",
    "#print(agent_futures.shape)\n",
    "print(agent_pasts[3,:,:])\n",
    "print(player_past)\n",
    "print(player_future)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [py3env]",
   "language": "python",
   "name": "Python [py3env]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
